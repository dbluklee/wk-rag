import csv
import os
import glob
from typing import List

class CSVChunk:
    """CSV ì²­í¬ ê°ì²´ (LangChain Documentì™€ ìœ ì‚¬í•œ êµ¬ì¡°)"""
    def __init__(self, page_content: str, metadata: dict):
        self.page_content = page_content
        self.metadata = metadata

def load_csv_from_docs():
    """docs í´ë”ì—ì„œ CSV íŒŒì¼ë“¤ì„ ë¡œë“œ"""
    docs_path = "./docs"
    
    if not os.path.exists(docs_path):
        print("âŒ docs í´ë”ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return None
    
    csv_files = glob.glob(os.path.join(docs_path, "*.csv"))
    
    if len(csv_files) == 0:
        print("âŒ CSV íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
        return None
    
    print(f"ğŸ“ ë°œê²¬ëœ CSV íŒŒì¼: {[os.path.basename(f) for f in csv_files]}")
    
    all_data = []
    
    for filename in csv_files:
        data = []
        
        # UTF-8 BOM ì œê±°ë¥¼ ìœ„í•´ utf-8-sig ì‚¬ìš©
        with open(filename, 'r', encoding='utf-8-sig') as file:
            reader = csv.DictReader(file)
            
            if not reader.fieldnames:
                print(f"âš ï¸ ê²½ê³ : {filename}ì— í—¤ë”ê°€ ì—†ìŠµë‹ˆë‹¤.")
                continue
            
            for row in reader:
                # í‚¤ ì´ë¦„ì˜ BOM ë° ê³µë°± ì œê±°
                cleaned_row = {}
                for key, value in row.items():
                    cleaned_key = key.replace('\ufeff', '').strip() if key else key
                    cleaned_row[cleaned_key] = value
                
                data.append(cleaned_row)
        
        if len(data) > 0:
            all_data.append({
                'filename': os.path.basename(filename),
                'data': data,
                'rows': len(data)
            })
            print(f"ğŸ“Š {os.path.basename(filename)}: {len(data)}í–‰ ë¡œë“œ")
    
    if len(all_data) == 0:
        print("âŒ CSV íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
        return None
    
    return all_data

def chunk_csv_files(csv_data_list: List) -> List[CSVChunk]:
    """
    CSV ë°ì´í„°ë¥¼ í–‰ ê¸°ì¤€ìœ¼ë¡œ ì²­í‚¹
    ê° í–‰ì„ í—¤ë”(ë©”íƒ€ë°ì´í„°)ì™€ page_content(ì£¼ìš” ë‚´ìš©)ë¡œ ë¶„ë¦¬
    """
    if not csv_data_list:
        print("âŒ CSV ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return []
    
    chunks = []
    
    for file_data in csv_data_list:
        filename = file_data['filename']
        data = file_data['data']
        
        print(f"\nğŸ“– CSV íŒŒì¼ ì²˜ë¦¬: {filename}")
        print(f"âœ‚ï¸ í–‰ ê¸°ì¤€ìœ¼ë¡œ ì²­í‚¹ ì¤‘...")
        
        processed_count = 0
        
        for idx, row in enumerate(data):
            # Space Nameì´ 'ë‚´ ì—…ë¬´ ë¦¬ìŠ¤íŠ¸' ë˜ëŠ” 'ì´ì‚¬íšŒ'ì¸ ê²½ìš° ìŠ¤í‚µ
            space_name = row.get('Space Name', '')
            if space_name in ['ë‚´ ì—…ë¬´ ë¦¬ìŠ¤íŠ¸', 'ì´ì‚¬íšŒ']:
                continue
            
            # í—¤ë” (ë©”íƒ€ë°ì´í„°) êµ¬ì„±
            header_parts = []
            header_parts.append(f"Source: {filename}")
            
            task_id = row.get('Task ID', '')
            if task_id and str(task_id).strip():
                header_parts.append(f"TaskID: {task_id}")
            
            if row.get('Parent ID'):
                header_parts.append(f"ParentID: {row['Parent ID']}")
            if row.get('Tags'):
                header_parts.append(f"Tags: {row['Tags']}")
            if row.get('List Name'):
                header_parts.append(f"ListName: {row['List Name']}")
            if row.get('Folder Name'):
                header_parts.append(f"FolderName: {row['Folder Name']}")
            if row.get('Space Name'):
                header_parts.append(f"SpaceName: {row['Space Name']}")
            if row.get('Comments'):
                header_parts.append(f"Comments: {row['Comments']}")
            if row.get('Date Created Text'):
                header_parts.append(f"DateCreated: {row['Date Created Text']}")
            
            header = ", ".join(header_parts)
            
            # Page Content (ì£¼ìš” ë‚´ìš©) êµ¬ì„± - í—¤ë” ì •ë³´ë„ í¬í•¨í•˜ì—¬ ê²€ìƒ‰ ê°€ëŠ¥í•˜ê²Œ í•¨
            content_parts = []
            
            # 1. í—¤ë” ì •ë³´ (ê²€ìƒ‰ ê°€ëŠ¥í•˜ë„ë¡ page_contentì— í¬í•¨)
            content_parts.append("=== ì‘ì—… ì •ë³´ ===")
            
            if task_id and str(task_id).strip():
                content_parts.append(f"ì‘ì—…ID: {task_id}")
            
            task_name = row.get('Task Name', '')
            if task_name and str(task_name).strip():
                content_parts.append(f"ì‘ì—…ëª…: {task_name.strip()}")
            
            parent_id = row.get('Parent ID', '')
            if parent_id and str(parent_id).strip() and parent_id != 'null':
                content_parts.append(f"ìƒìœ„ì‘ì—…ID: {parent_id}")
            
            list_name = row.get('List Name', '')
            if list_name:
                content_parts.append(f"ë¦¬ìŠ¤íŠ¸: {list_name}")
            
            folder_name = row.get('Folder Name', '')
            if folder_name:
                content_parts.append(f"í´ë”: {folder_name}")
            
            space_name = row.get('Space Name', '')
            if space_name:
                content_parts.append(f"ìŠ¤í˜ì´ìŠ¤: {space_name}")
            
            tags = row.get('Tags', '')
            if tags and tags != '[]':
                content_parts.append(f"íƒœê·¸: {tags}")
            
            assignees = row.get('Assignees', '')
            if assignees and assignees != '[]':
                content_parts.append(f"ë‹´ë‹¹ì: {assignees}")
            
            date_created = row.get('Date Created Text', '')
            if date_created and str(date_created).strip():
                content_parts.append(f"ìƒì„±ì¼: {date_created}")
            
            # 2. ì‘ì—… ë‚´ìš©
            if row.get('Task Content'):
                content_parts.append("")
                content_parts.append("=== ì‘ì—… ë‚´ìš© ===")
                content_parts.append(row['Task Content'])
            
            # 3. ëŒ“ê¸€ ì •ë³´
            comments = row.get('Comments', '')
            if comments and comments != '[]':
                content_parts.append("")
                content_parts.append("=== ëŒ“ê¸€ ===")
                content_parts.append(f"ëŒ“ê¸€: {comments}")
            
            page_content = "\n".join(content_parts)
            
            # ë©”íƒ€ë°ì´í„° êµ¬ì„±
            metadata = {
                'source': filename,
                'chunk_id': f"{filename}_{processed_count+1}",
                'row_number': idx + 1,
                'task_id': task_id,
                'task_name': task_name.strip() if task_name else '',
                'list_name': row.get('List Name', ''),
                'folder_name': row.get('Folder Name', ''),
                'space_name': row.get('Space Name', ''),
                'date_created': row.get('Date Created Text', ''),
                'header': header
            }
            
            # CSVChunk ê°ì²´ ìƒì„±
            chunk = CSVChunk(page_content=page_content, metadata=metadata)
            chunks.append(chunk)
            processed_count += 1
        
        print(f"ğŸ“Š {filename}: {processed_count}ê°œ ì²­í¬ ìƒì„± (ì´ {len(data)}í–‰ ì¤‘ {len(data) - processed_count}í–‰ í•„í„°ë§ë¨)")
    
    print(f"\nâœ… ì´ {len(chunks)}ê°œ CSV ì²­í¬ ì²˜ë¦¬ ì™„ë£Œ")
    return chunks

def save_csv_chunks_to_file(chunks: List[CSVChunk], output_file: str = "./chunking/chunks/csv_chunks_output.txt"):
    """CSV ì²­í¬ë¥¼ íŒŒì¼ë¡œ ì €ì¥"""
    if not chunks:
        print("âš ï¸ ì €ì¥í•  ì²­í¬ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    try:
        with open(output_file, 'w', encoding='utf-8') as f:
            f.write(f"CSV ì²­í‚¹ ê²°ê³¼ - ì´ {len(chunks)}ê°œ ì²­í¬\n")
            f.write("=" * 80 + "\n\n")
            
            for i, chunk in enumerate(chunks, 1):
                f.write(f"=== CSV CHUNK {i}: {chunk.metadata['chunk_id']} ===\n")
                f.write(f"Source: {chunk.metadata['source']} (Row {chunk.metadata['row_number']})\n")
                f.write(f"Task ID: {chunk.metadata['task_id']}\n")
                f.write(f"Task Name: {chunk.metadata['task_name']}\n")
                f.write(f"List Name: {chunk.metadata['list_name']}\n")
                f.write(f"Folder Name: {chunk.metadata['folder_name']}\n")
                f.write(f"Space Name: {chunk.metadata['space_name']}\n")
                f.write(f"Date Created: {chunk.metadata['date_created']}\n\n")
                
                f.write("HEADER:\n")
                f.write(f"{chunk.metadata['header']}\n\n")
                
                f.write("PAGE_CONTENT:\n")
                f.write(f"{chunk.page_content}\n")
                f.write("\n" + "=" * 80 + "\n\n")
        
        print(f"ğŸ’¾ CSV ì²­í¬ê°€ '{output_file}'ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
        
    except Exception as e:
        print(f"âŒ íŒŒì¼ ì €ì¥ ì˜¤ë¥˜: {e}")

def chunk_csv_file(file_path: str = None) -> List[CSVChunk]:
    """
    Main.pyì—ì„œ í˜¸ì¶œí•  ìˆ˜ ìˆëŠ” ë©”ì¸ í•¨ìˆ˜
    """
    print(f"\nğŸ“ CSV íŒŒì¼ ì²­í‚¹ ì‹œì‘...")
    
    # CSV íŒŒì¼ ë¡œë“œ
    csv_data = load_csv_from_docs()
    
    if not csv_data:
        print("âŒ CSV ë°ì´í„°ë¥¼ ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return []
    
    # ì²­í‚¹ ìˆ˜í–‰
    chunks = chunk_csv_files(csv_data)
    
    # íŒŒì¼ë¡œ ì €ì¥
    if chunks:
        save_csv_chunks_to_file(chunks)
    
    return chunks